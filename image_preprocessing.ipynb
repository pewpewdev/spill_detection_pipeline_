{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (8.3.107)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (3.9.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (6.1.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.55.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.107 üöÄ Python-3.10.15 torch-2.6.0 CPU (Apple M1)\n",
      "Setup complete ‚úÖ (8 CPUs, 8.0 GB RAM, 164.3/228.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-2.0.5-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from albumentations) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from albumentations) (1.14.1)\n",
      "Requirement already satisfied: PyYAML in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from albumentations) (6.0.2)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting albucore==0.0.23 (from albumentations)\n",
      "  Downloading albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.23->albumentations)\n",
      "  Downloading stringzilla-3.12.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (80 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.23->albumentations)\n",
      "  Downloading simsimd-6.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (66 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading pydantic_core-2.33.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/cilvosimon/Downloads/Live_face_recognition/face_env/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.9.2->albumentations)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading albumentations-2.0.5-py3-none-any.whl (290 kB)\n",
      "Downloading albucore-0.0.23-py3-none-any.whl (14 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading simsimd-6.2.1-cp310-cp310-macosx_11_0_arm64.whl (93 kB)\n",
      "Downloading stringzilla-3.12.4-cp310-cp310-macosx_11_0_arm64.whl (79 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: stringzilla, simsimd, typing-inspection, pydantic-core, opencv-python-headless, annotated-types, pydantic, albucore, albumentations\n",
      "Successfully installed albucore-0.0.23 albumentations-2.0.5 annotated-types-0.7.0 opencv-python-headless-4.11.0.86 pydantic-2.11.3 pydantic-core-2.33.1 simsimd-6.2.1 stringzilla-3.12.4 typing-inspection-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import albumentations as A\n",
    "\n",
    "# Paths\n",
    "image_dir = 'images'\n",
    "label_dir = 'label'\n",
    "output_img_dir = 'images_aug'\n",
    "output_label_dir = 'labels_aug'\n",
    "\n",
    "# Augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.Resize(640, 640),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.RandomBrightnessContrast(0.1, 0.1, p=0.5)\n",
    "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n",
    "\n",
    "# Conversion functions\n",
    "def yolo_to_voc(x_center, y_center, w, h, img_w, img_h):\n",
    "    x_min = int((x_center - w / 2) * img_w)\n",
    "    y_min = int((y_center - h / 2) * img_h)\n",
    "    x_max = int((x_center + w / 2) * img_w)\n",
    "    y_max = int((y_center + h / 2) * img_h)\n",
    "    return x_min, y_min, x_max, y_max\n",
    "\n",
    "def voc_to_yolo(x_min, y_min, x_max, y_max, img_w, img_h):\n",
    "    x_center = ((x_min + x_max) / 2) / img_w\n",
    "    y_center = ((y_min + y_max) / 2) / img_h\n",
    "    w = (x_max - x_min) / img_w\n",
    "    h = (y_max - y_min) / img_h\n",
    "    return x_center, y_center, w, h\n",
    "\n",
    "# Process all images\n",
    "for img_path in glob.glob(os.path.join(image_dir, '*.jpg')):\n",
    "    filename = os.path.basename(img_path).split('.')[0]\n",
    "    label_path = os.path.join(label_dir, filename + '.txt')\n",
    "\n",
    "    image = cv2.imread(img_path)\n",
    "    img_h, img_w = image.shape[:2]\n",
    "\n",
    "    # Skip if label file doesn't exist\n",
    "    if not os.path.exists(label_path):\n",
    "        continue\n",
    "\n",
    "    # Read YOLO labels\n",
    "    with open(label_path, 'r') as f:\n",
    "        yolo_bboxes = []\n",
    "        class_labels = []\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            cls = int(parts[0])\n",
    "            x_c, y_c, w, h = map(float, parts[1:])\n",
    "            x_min, y_min, x_max, y_max = yolo_to_voc(x_c, y_c, w, h, img_w, img_h)\n",
    "            yolo_bboxes.append([x_min, y_min, x_max, y_max])\n",
    "            class_labels.append(cls)\n",
    "\n",
    "    # Apply augmentation\n",
    "    augmented = transform(image=image, bboxes=yolo_bboxes, class_labels=class_labels)\n",
    "    aug_img = augmented['image']\n",
    "    aug_bboxes = augmented['bboxes']\n",
    "    aug_labels = augmented['class_labels']\n",
    "\n",
    "    # Save augmented image\n",
    "    aug_img_name = filename + '_aug.jpg'\n",
    "    cv2.imwrite(os.path.join(output_img_dir, aug_img_name), aug_img)\n",
    "\n",
    "    # Convert bboxes back to YOLO and save labels\n",
    "    aug_img_h, aug_img_w = aug_img.shape[:2]\n",
    "    with open(os.path.join(output_label_dir, filename + '_aug.txt'), 'w') as f:\n",
    "        for bbox, cls in zip(aug_bboxes, aug_labels):\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "            x_c, y_c, w, h = voc_to_yolo(x_min, y_min, x_max, y_max, aug_img_w, aug_img_h)\n",
    "            f.write(f\"{cls} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set your augmented image and label folder paths\n",
    "image_dir = 'images_aug'\n",
    "label_dir = 'labels_aug'\n",
    "class_names = ['spill']  # update with your actual class list if needed\n",
    "\n",
    "def draw_yolo_box(image_path, label_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            class_id, x_center, y_center, bw, bh = map(float, line.strip().split())\n",
    "            x1 = int((x_center - bw / 2) * w)\n",
    "            y1 = int((y_center - bh / 2) * h)\n",
    "            x2 = int((x_center + bw / 2) * w)\n",
    "            y2 = int((y_center + bh / 2) * h)\n",
    "\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(img, class_names[int(class_id)], (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.5, (0, 255, 0), 1)\n",
    "\n",
    "    cv2.imshow('Check Augmentation', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Loop through and check a few examples\n",
    "for file in os.listdir(image_dir):\n",
    "    if file.endswith('.jpg') or file.endswith('.png'):\n",
    "        img_path = os.path.join(image_dir, file)\n",
    "        label_path = os.path.join(label_dir, file.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "        if os.path.exists(label_path):\n",
    "            draw_yolo_box(img_path, label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "image_dir = 'images_aug'\n",
    "label_dir = 'labels_aug'\n",
    "output_dir = 'checked_images'  # folder to save images with boxes\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Class names (change as needed)\n",
    "class_names = ['spill']\n",
    "\n",
    "def draw_yolo_box_and_save(image_path, label_path, save_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w, _ = img.shape\n",
    "\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            class_id, x_center, y_center, bw, bh = map(float, line.strip().split())\n",
    "            x1 = int((x_center - bw / 2) * w)\n",
    "            y1 = int((y_center - bh / 2) * h)\n",
    "            x2 = int((x_center + bw / 2) * w)\n",
    "            y2 = int((y_center + bh / 2) * h)\n",
    "\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(img, class_names[int(class_id)], (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Save the image with boxes\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "# Process and save all images with bounding boxes\n",
    "for file in os.listdir(image_dir):\n",
    "    if file.endswith('.jpg') or file.endswith('.png'):\n",
    "        img_path = os.path.join(image_dir, file)\n",
    "        label_path = os.path.join(label_dir, file.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            save_path = os.path.join(output_dir, file)\n",
    "            draw_yolo_box_and_save(img_path, label_path, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Split complete!\n",
      "Training images: 61\n",
      "Validation images: 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Set paths\n",
    "base_path = 'spill_detection'\n",
    "image_dir = os.path.join(base_path, 'tot_images')\n",
    "label_dir = os.path.join(base_path, 'tot_labels')\n",
    "\n",
    "# Target folders\n",
    "train_img_dir = os.path.join(base_path, 'images/train')\n",
    "val_img_dir   = os.path.join(base_path, 'images/val')\n",
    "train_lbl_dir = os.path.join(base_path, 'labels/train')\n",
    "val_lbl_dir   = os.path.join(base_path, 'labels/val')\n",
    "\n",
    "# Make sure target dirs exist\n",
    "for d in [train_img_dir, val_img_dir, train_lbl_dir, val_lbl_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# List image files\n",
    "all_images = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))]\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# 80/20 split\n",
    "split_index = int(len(all_images) * 0.8)\n",
    "train_imgs = all_images[:split_index]\n",
    "val_imgs   = all_images[split_index:]\n",
    "\n",
    "# Copy function\n",
    "def copy_files(img_list, target_img_dir, target_lbl_dir):\n",
    "    for img_file in img_list:\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        lbl_file = img_file.rsplit('.', 1)[0] + '.txt'\n",
    "        lbl_path = os.path.join(label_dir, lbl_file)\n",
    "\n",
    "        shutil.copy2(img_path, target_img_dir)\n",
    "        if os.path.exists(lbl_path):\n",
    "            shutil.copy2(lbl_path, target_lbl_dir)\n",
    "\n",
    "# Copy to respective folders\n",
    "copy_files(train_imgs, train_img_dir, train_lbl_dir)\n",
    "copy_files(val_imgs,   val_img_dir,   val_lbl_dir)\n",
    "\n",
    "print(f\"‚úÖ Split complete!\")\n",
    "print(f\"Training images: {len(train_imgs)}\")\n",
    "print(f\"Validation images: {len(val_imgs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
